EfficientNet_Fine_Tuning
-----
![image](https://github.com/user-attachments/assets/8a0f6bbe-6072-42f5-92e9-bb89866074b0)



프로젝트 소개
----
이 프로젝트는 224 x 224 이미지 사이즈에 최적화된 EfficientNetB0 아키텍처를 전이학습하여 강아지의 감정을 학습하고, 새로운 이미지를 입력받아 해당 감정에 대한 예측을 수행하는 프로젝트

프로젝트 전체 과정 및 미세조정 부분
---
![image](https://github.com/user-attachments/assets/c3a34098-b88b-48d3-b315-de01965a7dc0)


주요 기능
----
● 데이터 수집 및 전처리 : 다양한 강아지 감정 이미지를 수집하고, 크기를 조정하여 모델 학습에 적합한 형태로 전처리

● 데이터 증강: 이미지 회전, 뒤집기, 대비 조정을 통해 데이터의 다양성을 높이고, 모델의 일반화 성능 향상

● 모델 구축 및 훈련 : EfficientNetB0을 기반으로 하는 전이 학습 모델을 구축하여 강아지의 감정을 분류하는 학습 진행

● 레이어 동결 : 초기 훈련 시, EfficientNetB0의 대부분 레이어를 동결하여 기본적인 특징 추출 기능 유지하며, 데이터셋의 작은 크기에 적합하도록 함

● 최종 레이어 학습 : 최상위 레이어만을 학습하여 강아지 감정을 분류하는 기능을 학습. 이후, 특정 레이어(ex - 마지막 30개 레이어)의 동결을 해제하여 미세 조정을 통해 모델 성능 향상

● 예측 및 시각화 : 사용자로부터 입력받은 이미지를 모델에 전달하여 감정을 예측하고, 예측 결과를 시각적으로 표시

● 결과 출력 : 예측된 감정의 확률과 함께, 해당 감정의 클래스를 시각적으로 출력

미세 조정 부분
---
● GlobalAveragePooling2D를 사용한 이유 : EfficientNetB0 모델에서는 GlobalAveragePooling2D가 효과적으로 동작한다고 알려져 있으며, 전역 평균 풀링층은 특성 맵에서 평균을 계산하여 각 샘플의 특성 맵마다 하나의 숫자를 출력하는데, 이는 모델의 파라미터 수를 줄여 과적합을 방지하고, 모델의 계산량을 줄여 효율성을 높이는 데 도움이 됨

● 레이어를 동결 하는 이유 : 기존에 잘 학습된 특징을 그대로 활용하여 새로운 데이터에 빠르게 적응하면서도, 과적합을 방지하고 학습의 효율성을 높이기 위해 사용

● 동결 해제하고 다시 훈련하는 이유 : 사전 학습된 모델의 상위 층 레이어들은 Imagenet 데이터셋에 특화된 고수준의 특징을 학습한 레이어들이므로 새로운 데이터셋에서는 이 고수준 특징이 나의 데이터셋의 특성과 맞지 않을 수 있으므로 일부 상위층을 재학습하면 새로운 데이터셋에 특화된 특징을 학습할 수 있기 때문에 다시 훈련


개발 환경
---
● Google Colab : 클라우드 기반 Python 개발 환경으로 , GPU를 사용한 딥러닝 모델 학습에 사용

● Python : 주요 프로그래밍 언어로 사용

● Google Drive : 데이터를 저장하고 불러오는 파일 시스템으로 사용

기술 스택
--
● Tensorflow & Keras : 딥러닝 모델 구축 및 학습 및 사전 학습된 EfficientNetB0 모델 로드를 위해 사용 

● OpenCV : 이미지 전처리 및 변환에 사용(이미지 파일 로드 및 색상 변환 등)

● Scikit-learn : 학습 데이터와 검증 데이터를 분리하는 데 사용 (train_test_split 함수)

● Matplotlib : 학습 과정에서의 정확도 및 손실 그래프 시각화

● tf.data API : Tensorflow 데이터셋 생성 및 배치 처리에 사용

● Data Augmentation : 랜덤 회전 , 수평 플립 , 대비 조정 등을 사용하여 데이터 증강

성능 평가
---
![image](https://github.com/user-attachments/assets/3869c5f6-bc5b-4f6f-8954-9e34f7e830b7)

● 훈련과 검증 데이터에서 각각 98%, 99%의 정확도와 4%, 0.7%의 손실로 모델이 데이터를 효과적으로 일반화함을 확인

이미지 예측
---
![image](https://github.com/user-attachments/assets/d31a087a-1386-4e2f-9a32-d6e864ccf554)


● 모델의 학습 정확도와 손실이 안정적으로 감소/증가하여, 과적합 없이 일관된 성능 향상

